{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8173612,"sourceType":"datasetVersion","datasetId":4837850}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nimport time \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision.datasets as datasets\nfrom torchmetrics import Accuracy, Precision, Recall, F1Score","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:16:08.210962Z","iopub.execute_input":"2024-04-29T20:16:08.211850Z","iopub.status.idle":"2024-04-29T20:16:08.217449Z","shell.execute_reply.started":"2024-04-29T20:16:08.211818Z","shell.execute_reply":"2024-04-29T20:16:08.216428Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, random_split\n\nclass CustomDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = sorted(os.listdir(data_dir))\n\n        self.images = []\n        self.labels = []\n\n        for i, class_name in enumerate(self.classes):\n            class_dir = os.path.join(data_dir, class_name)\n            for image_name in os.listdir(class_dir):\n                image_path = os.path.join(class_dir, image_name)\n                self.images.append(image_path)\n                self.labels.append(i)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:16:11.598360Z","iopub.execute_input":"2024-04-29T20:16:11.598738Z","iopub.status.idle":"2024-04-29T20:16:11.608531Z","shell.execute_reply.started":"2024-04-29T20:16:11.598704Z","shell.execute_reply":"2024-04-29T20:16:11.607642Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_data_loaders(dataset_path, train_size=0.8, batch_size=32, shuffle=True):\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(), \n    ])\n\n    dataset = CustomDataset(dataset_path, transform=transform)\n\n    # Define sizes for train, validation, and test sets\n    train_size = int(train_size * len(dataset))\n    val_size = (len(dataset) - train_size) // 2\n    test_size = len(dataset) - train_size - val_size\n\n    # Split dataset into train, validation, and test sets\n    train_data, val_data, test_data = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n\n    # Create DataLoader instances for training, validation, and testing\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:16:15.312455Z","iopub.execute_input":"2024-04-29T20:16:15.313124Z","iopub.status.idle":"2024-04-29T20:16:15.321084Z","shell.execute_reply.started":"2024-04-29T20:16:15.313090Z","shell.execute_reply":"2024-04-29T20:16:15.320099Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define the dataset path\ndataset_path = \"/kaggle/input/plant-leave-diseases-dataset-with-augmentation/Plant_leave_diseases_dataset_with_augmentation\"\n\n# Define batch size for DataLoader\nbatch_size = 32\n\n# Create DataLoader instances for training, validation, and testing\ntrain_loader, val_loader, test_loader = create_data_loaders(dataset_path, batch_size=batch_size)\n\n# Check the lengths of the loaders\nprint(f\"Number of batches in train_loader: {len(train_loader)}\")\nprint(f\"Number of batches in val_loader: {len(val_loader)}\")\nprint(f\"Number of batches in test_loader: {len(test_loader)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:16:18.702630Z","iopub.execute_input":"2024-04-29T20:16:18.703008Z","iopub.status.idle":"2024-04-29T20:16:40.853436Z","shell.execute_reply.started":"2024-04-29T20:16:18.702968Z","shell.execute_reply":"2024-04-29T20:16:40.852280Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of batches in train_loader: 1538\nNumber of batches in val_loader: 193\nNumber of batches in test_loader: 193\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfor image, label in test_loader:\n    \n    min_val = torch.min(image)\n    mean_val = torch.mean(image)\n    max_val = torch.max(image)\n    \n    print(min_val.item(), mean_val.item(), max_val.item())\n    break\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:16:57.322620Z","iopub.execute_input":"2024-04-29T20:16:57.322997Z","iopub.status.idle":"2024-04-29T20:16:57.824606Z","shell.execute_reply.started":"2024-04-29T20:16:57.322958Z","shell.execute_reply":"2024-04-29T20:16:57.823650Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0.0 0.4681517779827118 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclass MultiClassCNN(nn.Module):\n    def __init__(self):\n        super(MultiClassCNN, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 32, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.flatten = nn.Flatten()\n        self.fc_block = nn.Sequential(\n            nn.Linear(32 * 62 * 62, 512),  # Calculated based on the output size after convolutions\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 39)  # 39 classes\n        ) \n\n    def forward(self, x):\n        x = self.conv_block(x)\n        x = self.flatten(x)\n        x = self.fc_block(x)\n        return x \n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:17:04.602725Z","iopub.execute_input":"2024-04-29T20:17:04.603101Z","iopub.status.idle":"2024-04-29T20:17:04.611809Z","shell.execute_reply.started":"2024-04-29T20:17:04.603072Z","shell.execute_reply":"2024-04-29T20:17:04.610758Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Initialization of the model\nmodel = MultiClassCNN()\n\n# Definition of loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# Initialization of metrics\naccuracy = Accuracy(task='multiclass', num_classes=39, average='macro')\nprecision = Precision(task='multiclass', num_classes=39, average='macro')\nrecall = Recall(task='multiclass', num_classes=39, average='macro')\nf1 = F1Score(task='multiclass',num_classes=39, average='macro')\nval_accuracy = Accuracy(task='multiclass', num_classes=39, average='macro')  # Initialize validation accuracy outside the loop\nepoch_losses= []\nval_losses=[]\n# Training loop\nfor epoch in range(10):  # Number of epochs\n    start_time = time.time()  # Start time\n    \n    running_loss = 0.0\n    model.train()  # Set model to training mode\n    \n    for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n            # Reset gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Calculate loss\n            loss = criterion(outputs, labels)\n\n            # Backward pass\n            loss.backward()\n\n            # Update model parameters\n            optimizer.step()\n\n            # Update running loss\n            running_loss += loss.item()\n\n            # Update metrics\n            accuracy.update(outputs, labels)\n            precision.update(outputs, labels)\n            recall.update(outputs, labels)\n            f1.update(outputs, labels)\n\n    \n    # Calculate metrics after each epoch\n    epoch_loss = running_loss / len(train_loader)\n    epoch_losses.append(epoch_loss)  # Store epoch loss\n    acc = accuracy.compute()\n    prec = precision.compute()\n    rec = recall.compute()\n    f1_score = f1.compute()\n    \n    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1_score:.4f}\")\n    \n    # Validation loop\n    val_loss = 0.0\n    model.eval()  # Set model to evaluation mode\n    \n    for val_images, val_labels in tqdm(val_loader, desc=\"Validation\"):\n        with torch.no_grad():\n            val_outputs = model(val_images)\n            val_loss += criterion(val_outputs, val_labels).item()\n            val_accuracy.update(val_outputs, val_labels)\n    val_acc = val_accuracy.compute()\n    val_loss /= len(val_loader)\n    val_losses.append(val_loss)  # Store validation loss\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n    \n    # Elapsed time\n    end_time = time.time()\n    epoch_time = end_time - start_time\n    print(f\"Time elapsed for epoch {epoch+1}: {epoch_time:.2f} seconds\")\n\n# Plotting\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, len(epoch_losses) + 1), epoch_losses, label='Train Loss', marker='o')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='o')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Losses')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:17:15.161261Z","iopub.execute_input":"2024-04-29T20:17:15.161619Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1538/1538 [50:27<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 1.0958\nAccuracy: 0.6102, Precision: 0.6358, Recall: 0.6102, F1 Score: 0.6197\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 193/193 [02:56<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.6574, Validation Accuracy: 0.7468\nTime elapsed for epoch 1: 3203.75 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1538/1538 [44:53<00:00,  1.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4309\nAccuracy: 0.7202, Precision: 0.7365, Recall: 0.7202, F1 Score: 0.7271\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 193/193 [01:35<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.4293, Validation Accuracy: 0.7927\nTime elapsed for epoch 2: 2788.89 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1538/1538 [45:06<00:00,  1.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2535\nAccuracy: 0.7801, Precision: 0.7927, Recall: 0.7801, F1 Score: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 193/193 [02:06<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.4652, Validation Accuracy: 0.8044\nTime elapsed for epoch 3: 2832.92 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 1538/1538 [45:35<00:00,  1.78s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.1741\nAccuracy: 0.8177, Precision: 0.8281, Recall: 0.8177, F1 Score: 0.8225\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 193/193 [01:53<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.7246, Validation Accuracy: 0.7999\nTime elapsed for epoch 4: 2849.16 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 1538/1538 [44:58<00:00,  1.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.1247\nAccuracy: 0.8445, Precision: 0.8533, Recall: 0.8445, F1 Score: 0.8486\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 193/193 [02:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.5342, Validation Accuracy: 0.8061\nTime elapsed for epoch 5: 2820.44 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 1538/1538 [44:09<00:00,  1.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.1016\nAccuracy: 0.8640, Precision: 0.8717, Recall: 0.8640, F1 Score: 0.8676\n","output_type":"stream"},{"name":"stderr","text":"Validation:   0%|          | 0/193 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-27T09:54:19.409029Z","iopub.execute_input":"2024-04-27T09:54:19.409390Z","iopub.status.idle":"2024-04-27T09:54:19.452693Z","shell.execute_reply.started":"2024-04-27T09:54:19.409363Z","shell.execute_reply":"2024-04-27T09:54:19.451565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}